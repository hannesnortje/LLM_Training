<mxfile host="65bd71144e">
    <diagram name="Balanced Training Architecture" id="architecture">
        <mxGraphModel dx="1170" dy="711" grid="1" gridSize="10" guides="1" tooltips="1" connect="1" arrows="1" fold="1" page="1" pageScale="1" pageWidth="2400" pageHeight="1800" math="0" shadow="0">
            <root>
                <mxCell id="0"/>
                <mxCell id="1" parent="0"/>
                <mxCell id="title" value="Web4 Balanced LoRA Training Architecture" style="text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontSize=32;fontStyle=1" parent="1" vertex="1">
                    <mxGeometry x="400" y="20" width="1600" height="50" as="geometry"/>
                </mxCell>
                <mxCell id="subtitle" value="RAG-First Pipeline: Train Patterns, Reference History, Swappable Tools | Target: 37K trained samples (~20M tokens) + 12K RAG tool samples from 534 PDCAs" style="text;html=1;strokeColor=none;fillColor=#E3F2FD;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=1;fontSize=16;fontStyle=2" parent="1" vertex="1">
                    <mxGeometry x="400" y="80" width="1600" height="35" as="geometry"/>
                </mxCell>
                <object label="&lt;font color=&quot;#1565C0&quot;&gt;ðŸ¤– BASE MODEL&lt;/font&gt;&#xa;&#xa;Qwen/Qwen2.5-Coder-7B-Instruct&#xa;(HuggingFace - Full Precision)&#xa;&#xa;For Inference: qwen2.5-coder:7b-instruct-q4_K_M" tooltip="The base model is Qwen2.5-Coder 7B Instruct, chosen for its strong code generation capabilities and 7 billion parameters optimized for coding tasks. Training uses the full precision model from HuggingFace to maximize learning quality during LoRA fine-tuning. After training, the adapter is merged with the base model and quantized to Q4_K_M format for deployment via Ollama. This quantization reduces model size from 14GB to 4GB while maintaining 95 percent quality, enabling fast inference on M1 Mac hardware with 32GB RAM and MPS backend. The model architecture includes 28 transformer layers, 4096 hidden dimensions, 32 attention heads, 32768 context window, and supports 100+ programming languages with particular strength in Python, TypeScript, JavaScript, Java, and C++. The base model already understands general programming concepts like OOP, error handling, testing, and documentation - the LoRA fine-tuning teaches it Web4-specific conventions like 5-layer architecture, Radical OOP, empty constructor pattern, scenario-based state management, Vitest testing framework, and PDCA methodology for continuous improvement." id="base-model">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#BBDEFB;strokeColor=#1565C0;strokeWidth=4;fontSize=14;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="900" y="150" width="600" height="140" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#2E7D32&quot;&gt;ðŸŽ¯ LORA ADAPTER (Trained Knowledge)&lt;/font&gt;&#xa;&#xa;37,000 samples (~20M tokens)&#xa;Patterns &amp; Methodology (95% Web4, 3% tools, 2% guardrails)&#xa;r=16, alpha=32, dropout=0.05&#xa;Training: 8-11 hours on M1 Mac" tooltip="The LoRA adapter is a small trainable module (approximately 80MB, reduced from 100MB) that learns Web4-specific patterns without modifying the base model. LoRA uses rank decomposition to create two small matrices for each transformer layer, where rank r=16 means each matrix is much smaller than the original weight matrix. Training only these small matrices is 1000x faster and uses 10x less memory than full fine-tuning, enabling training on consumer hardware. The adapter contains 37,000 training samples totaling approximately 20M tokens (reduced from 46K/25M), carefully curated to teach Web4 methodology with optimal token efficiency: 95 percent Web4-specific patterns versus 74 percent in the old approach. Process Knowledge (5K samples) covering PDCA structure, TRON format, CMM1-4 framework, dual link format, and 12-step startup protocol. Code Patterns (18K samples) including empty constructor pattern, init method for scenario-based state, toScenario serialization, 5-layer architecture, and Radical OOP. Extracted PDCA Patterns (8K samples) with problem-solution pairs, debugging methodologies, architectural decisions, violation fixes, integration patterns, and collaboration patterns. Representative PDCAs (3K samples) from top 200-300 complete PDCAs selected by quality score. Generic Tool Awareness (1K samples, NEW) teaching the CONCEPT of tools with JSON structure and parameter passing, NOT specific IDE implementations. Guardrails (2K samples) for security violations and framework compliance. Training takes 8-11 hours on M1 Mac with MPS acceleration (20 percent faster due to reduced token count), monitoring loss convergence to 0.6-1.0 plateau and memory usage staying under 28GB." id="lora-adapter">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#C8E6C9;strokeColor=#2E7D32;strokeWidth=4;fontSize=14;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="900" y="320" width="600" height="140" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#F57F17&quot;&gt;ðŸ—„ï¸ THREE-TIER RAG ARCHITECTURE&lt;/font&gt;&#xa;&#xa;Tier 1: ChromaDB (Semantic Search)&#xa;Tier 2: Redis Graph (Breadcrumb Navigation)&#xa;Tier 3: SQLite (Temporal Queries)&#xa;&#xa;534 PDCAs â†’ ~2,670 chunks | All components indexed" tooltip="The three-tier RAG architecture is the cornerstone of the balanced training strategy, serving as both the data source for training sample generation and the runtime historical reference library. This hybrid design optimizes different query patterns: Tier 1 ChromaDB provides semantic search using vector embeddings, ideal for finding similar PDCAs or patterns. The 534 historical PDCAs are chunked into approximately 2,670 semantically complete chunks using PDCA-aware adaptive chunking that preserves document structure by splitting on section boundaries. Each chunk includes 15+ metadata fields covering temporal data, agent context, work context, task context, CMM compliance, and quality signals. Tier 2 Redis Graph stores breadcrumb navigation links between PDCAs, enabling fast graph traversal to implement the read-to-depth-3 principle. Graph queries are 50x faster than vector search for adjacency relationships. Tier 3 SQLite handles temporal queries efficiently, supporting fast date-range lookups and agent timeline tracking without scanning the entire vector database. This three-tier design provides single source of truth for all training data, intelligent sampling via semantic queries, natural deduplication through chunking, metadata-driven filtering, graph-aware context expansion, incremental refinement, and consistent methodology." id="rag-architecture">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#FFF9C4;strokeColor=#F57F17;strokeWidth=4;fontSize=14;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="50" y="150" width="750" height="480" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#E65100&quot;&gt;Tier 1: ChromaDB&lt;/font&gt;&#xa;Vector Embeddings&#xa;~2,670 PDCA chunks&#xa;15+ metadata fields&#xa;Semantic similarity search" tooltip="ChromaDB is an open-source vector database optimized for semantic search using embeddings. Each PDCA chunk is converted to a 768-dimensional vector using a sentence-transformer model, capturing semantic meaning beyond keyword matching. This enables queries to find relevant PDCAs even if they use different terminology. The chunks are stored with comprehensive metadata enabling filtered queries. ChromaDB uses HNSW index for fast approximate nearest neighbor search, returning results in approximately 500ms. The metadata fields enable precise filtering by chunk type, CMM level, task type, date, agent, and verification status. ChromaDB also indexes 3,477 TypeScript component files by layer and pattern, plus 238 process documents by role. During training sample generation, ChromaDB is queried thousands of times to extract patterns for the training dataset." id="chromadb">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#FFE0B2;strokeColor=#EF6C00;strokeWidth=2;fontSize=11;fontStyle=0;" parent="1" vertex="1">
                        <mxGeometry x="70" y="320" width="220" height="90" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#E65100&quot;&gt;Tier 2: Redis Graph&lt;/font&gt;&#xa;Breadcrumb links&#xa;534 nodes, PRECEDES edges&#xa;Fast graph traversal&#xa;Read to depth 3" tooltip="Redis Graph stores PDCA breadcrumb relationships as a graph database, enabling fast traversal of prev/next links extracted from PDCA metadata. Each of the 534 PDCAs becomes a node with properties, and PRECEDES edges connect chronologically related PDCAs. Graph queries are extremely fast (approximately 10ms) compared to vector search (approximately 500ms) because they use index lookups rather than similarity computation. The primary use case is read-to-depth-3: when semantic search finds a relevant PDCA, walk the graph backward and forward up to 3 levels deep to understand the full context. This implements the Web4 principle that context matters - a single PDCA in isolation may miss important background. Redis Graph uses sparse adjacency matrices for efficient traversal and supports Cypher-like query language. During training sample generation, graph expansion enriches semantic search results to include predecessor and successor context." id="redis-graph">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#FFE0B2;strokeColor=#EF6C00;strokeWidth=2;fontSize=11;fontStyle=0;" parent="1" vertex="1">
                        <mxGeometry x="310" y="320" width="220" height="90" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#E65100&quot;&gt;Tier 3: SQLite&lt;/font&gt;&#xa;Temporal metadata&#xa;Fast date-range queries&#xa;Agent/sprint aggregation&#xa;5ms query time" tooltip="SQLite stores temporal and categorical metadata in a relational schema optimized for fast date-range queries, agent timelines, and sprint aggregations. The pdca_timeline table contains pdca_id, timestamp, session, agent_name, agent_role, branch, sprint, cmm_level, and objective with appropriate indexes. Indexes enable sub-5ms queries which is 100x faster than scanning ChromaDB with metadata filters because SQL databases are optimized for structured queries with B-tree indexes. SQLite is also used for analytics: count PDCAs per day, identify most active agents, track CMM level distribution over time, measure sprint velocity. During training sample generation, temporal queries ensure diverse time period coverage to prevent temporal bias where the model only learns the newest patterns. SQLite is lightweight, requires no server, and integrates easily with Python. The three-tier design uses each database for its strength: ChromaDB for semantic understanding, Redis Graph for relationship traversal, SQLite for structured queries." id="sqlite">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#FFE0B2;strokeColor=#EF6C00;strokeWidth=2;fontSize=11;fontStyle=0;" parent="1" vertex="1">
                        <mxGeometry x="560" y="320" width="220" height="90" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#E65100&quot;&gt;ðŸ“š Collections&lt;/font&gt;&#xa;&#xa;â€¢ pdca_historical (534)&#xa;â€¢ components (3,477)&#xa;â€¢ process_docs (238)&#xa;â€¢ tool_examples (12K) â˜… NEW&#xa;â€¢ daily_buffer (transient)" tooltip="The RAG system organizes data into five ChromaDB collections. The pdca_historical collection contains 534 PDCAs as approximately 2,670 chunks - this is the permanent reference library with all historical PDCAs indexed with PDCA-aware adaptive chunking and comprehensive metadata. This collection never clears. The components collection indexes 3,477 TypeScript files organized by layer and pattern. The process_docs collection contains 238 documents including role-specific process documentation, CMM framework guides, PDCA templates, creation guides, decision frameworks, and compliance checklists. The tool_examples collection (NEW) stores 12,000 IDE-specific tool examples (10K Continue tools plus 2K negative examples) with metadata including tool_name, tool_ecosystem, tool_version, usage_pattern, and context_type. These tool examples are NOT trained into the LoRA adapter but are retrieved at runtime and injected into the context when the model needs to make tool calls. This enables IDE flexibility - switching from Continue to Cursor takes 5 minutes (clear Continue tools, index Cursor tools) versus 10-14 hours full retraining. The tool examples are swappable by ecosystem and support multiple IDEs simultaneously. The daily_buffer collection holds today work-in-progress and is transient, cleared nightly. During the evening training loop, daily_buffer is queried for untrained patterns, those patterns are trained into the adapter, and the buffer is cleared after moving data to permanent collections. This implements the incremental learning strategy where the model continuously improves from daily work." id="collections">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#FFE0B2;strokeColor=#EF6C00;strokeWidth=2;fontSize=11;fontStyle=0;" parent="1" vertex="1">
                        <mxGeometry x="70" y="440" width="700" height="130" as="geometry"/>
                    </mxCell>
                </object>
                <mxCell id="arrow-rag-to-training" value="" style="endArrow=classic;html=1;rounded=0;strokeWidth=4;strokeColor=#F57F17;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=0;entryY=0.5;entryDx=0;entryDy=0;" parent="1" source="rag-architecture" target="lora-adapter" edge="1">
                    <mxGeometry width="50" height="50" relative="1" as="geometry">
                        <mxPoint x="800" y="400" as="sourcePoint"/>
                        <mxPoint x="850" y="350" as="targetPoint"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="arrow-label-training" value="RAG-Driven&#xa;Sample Generation&#xa;37K samples" style="edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];fontSize=12;fontStyle=1;fontColor=#F57F17;fillColor=#FFF8E1;strokeColor=#F9A825;rounded=1;" parent="arrow-rag-to-training" vertex="1" connectable="0">
                    <mxGeometry x="-0.1" y="2" relative="1" as="geometry">
                        <mxPoint x="5" as="offset"/>
                    </mxGeometry>
                </mxCell>
                <object label="&lt;font color=&quot;#4A148C&quot;&gt;ðŸ“¦ TRAINING DATA BUCKETS (37K trained + 12K RAG tools)&lt;/font&gt;" tooltip="Training data is organized into 8 trained buckets plus RAG tool repository, teaching the model HOW TO CODE, HOW TO WORK, HOW TO SOLVE PROBLEMS, and WHAT NOT TO DO. The hybrid tool architecture splits tool knowledge: 1K generic tool awareness is trained (teaches CONCEPT of tools) while 12K IDE-specific examples stay in RAG (enables IDE switching without retraining). The trained buckets teach: HOW TO CODE - style_core (12K samples, 32 percent) extracts real Web4 architectural patterns from 3,477 TypeScript files including empty constructor, 5-layer architecture, Radical OOP, scenario-based state management. style_refactor (3K samples, 8 percent) shows code evolution and continuous improvement patterns. HOW TO WORK - process_framework (5K samples, 13 percent) teaches PDCA structure v3.2.4.2, TRON decision format, CMM1-4 progression, dual link format, 12-step startup protocol, verification checklists, and 50+ key behavioral lessons. HOW TO SOLVE PROBLEMS - domain_patterns (8K samples, 22 percent) extracts distilled problem-solving patterns from all 534 PDCAs including debugging methodologies, architectural decisions, integration patterns, and collaboration patterns. domain_representatives (3K samples, 8 percent) provides complete exemplary PDCAs selected by quality scoring to show end-to-end work structure. WHAT NOT TO DO - guardrails (2K samples, 5 percent) teaches security violations, Jest ban enforcement, manual operation prevention, and framework compliance. tool_awareness (1K samples, 3 percent) teaches generic tool-calling concepts with JSON structure and parameter passing, IDE-agnostic. eval (2K samples, 5 percent) is held-out test set NEVER trained. The RAG Tool Repository stores 12K IDE-specific tool examples with metadata for runtime injection, enabling 5-minute IDE switching versus 10-14 hours retraining." id="training-buckets">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#F3E5F5;strokeColor=#6A1B9A;strokeWidth=3;fontSize=14;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="1580" y="150" width="770" height="310" as="geometry"/>
                    </mxCell>
                </object>
                <object label="TRAINED (37K samples):&#xa;&#xa;HOW TO CODE: style_core 12K (32%) | style_refactor 3K (8%)&#xa;HOW TO WORK: process_framework 5K (13%)&#xa;HOW TO SOLVE: domain_patterns 8K (22%) | domain_representatives 3K (8%)&#xa;WHAT NOT TO DO: guardrails 2K (5%) | tool_awareness 1K (3%)&#xa;EVALUATION: eval 2K (5%) - HOLD-OUT&#xa;&#xa;RAG TOOLS (12K): tool_core 10K + tool_neg 2K (swappable)" tooltip="Clearer bucket naming that reflects what we actually teach the model. TRAINED samples (37K total, approximately 20M tokens): HOW TO CODE (15K samples, 40 percent) - style_core 12K samples teaches real Web4 architectural patterns from 3,477 TypeScript files: empty constructor pattern, 5-layer architecture, Radical OOP, scenario-based state management, init methods, toScenario serialization, component structure, and Vitest testing. style_refactor 3K samples shows code evolution patterns: CMM2 to CMM3 transformations, technical debt reduction, pattern application, refactoring journeys, and continuous improvement mindset. HOW TO WORK (5K samples, 13 percent) - process_framework 5K samples teaches the methodology: PDCA structure v3.2.4.2, TRON decision format, CMM1-4 progression and compliance, dual link format, 12-step startup protocol, verification checklists, collaboration patterns, feedback point recognition, and 50+ key behavioral lessons from trainAI. HOW TO SOLVE PROBLEMS (11K samples, 30 percent) - domain_patterns 8K samples extracts distilled problem-solving patterns from all 534 historical PDCAs: debugging methodologies, architectural decisions, violation fixes, integration patterns, collaboration patterns, and problem-solution pairs that capture Web4 domain wisdom. domain_representatives 3K samples provides complete exemplary PDCAs selected by quality scoring to show end-to-end work structure and full PDCA methodology in action. WHAT NOT TO DO (3K samples, 8 percent) - guardrails 2K samples teaches compliance: Jest ban enforcement, manual operation prevention, security violations, framework violations. tool_awareness 1K samples teaches generic tool-calling concepts: JSON structure, parameter passing, context awareness, IDE-agnostic patterns. EVALUATION (2K samples, 5 percent) - eval 2K samples is held-out test set stratified across all categories, NEVER trained, used for unbiased quality measurement. RAG TOOLS (12K samples, approximately 3.5MB): NOT trained into LoRA. Continue tools 10K plus negatives 2K stored in ChromaDB tool_examples collection with metadata. Runtime injection adds approximately 150ms latency but enables 5-minute IDE switching versus 10-14 hour retraining." id="bucket-detail">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#E1BEE7;strokeColor=#7B1FA2;strokeWidth=2;fontSize=11;fontStyle=0;" parent="1" vertex="1">
                        <mxGeometry x="1600" y="200" width="730" height="120" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#6A1B9A&quot;&gt;Token Distribution: ~20M trained + 3.5MB RAG tools&lt;/font&gt;&#xa;Avg 540 tokens/sample | 95% Web4, 3% tools, 2% guardrails&#xa;Optimized for M1 Mac (32GB RAM)&#xa;Training time: 8-11 hours (20% faster)" tooltip="The approximately 20M token budget is optimized for M1 Mac hardware with improved token efficiency. Token calculation: 37K samples times 540 average tokens per sample equals approximately 20M tokens, reduced from 25M (saving 5M tokens or 20 percent). The 540 token average accounts for short samples (100-200 tokens) for simple patterns, medium samples (400-800 tokens) for complete class implementations, and long samples (1200-1800 tokens) for full PDCA documents. This 20M token count enables faster training (8-11 hours versus 10-14 hours) while maintaining quality. Token distribution optimization: 95 percent Web4-specific patterns (versus 74 percent in old approach), 3 percent generic tool awareness (versus 22 percent for full tool training), 2 percent guardrails. This increases Web4 focus by 28 percent while maintaining tool capabilities through runtime RAG injection. The RAG tool repository stores 12K tool examples as approximately 3.5MB of text data, retrieved at runtime with approximately 150ms latency. Token efficiency strategies include PDCA patterns being distilled to save 60 percent tokens, code patterns using targeted extracts to save 40 percent tokens, representatives using smart variations to save 70 percent tokens, and tool examples staying in RAG to save 9K training samples. The 20M budget enables training sophisticated Web4 behaviors including 5-layer OOP architecture, empty constructor pattern, scenario-based state management, PDCA methodology with TRON format, CMM compliance, and framework adherence." id="token-dist">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#E1BEE7;strokeColor=#7B1FA2;strokeWidth=2;fontSize=11;fontStyle=0;" parent="1" vertex="1">
                        <mxGeometry x="1600" y="340" width="730" height="100" as="geometry"/>
                    </mxCell>
                </object>
                <mxCell id="arrow-training" value="" style="endArrow=classic;html=1;rounded=0;strokeWidth=4;strokeColor=#2E7D32;exitX=0.5;exitY=1;exitDx=0;exitDy=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;" parent="1" source="lora-adapter" target="trained-model" edge="1">
                    <mxGeometry width="50" height="50" relative="1" as="geometry">
                        <mxPoint x="1200" y="500" as="sourcePoint"/>
                        <mxPoint x="1200" y="600" as="targetPoint"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="arrow-label-lora" value="LoRA Training&lt;br&gt;8-11 hours&lt;br&gt;M1 Mac MPS" style="edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];fontSize=12;fontStyle=1;fontColor=#2E7D32;fillColor=#E8F5E9;strokeColor=#43A047;rounded=1;" parent="arrow-training" vertex="1" connectable="0">
                    <mxGeometry x="-0.1" y="2" relative="1" as="geometry">
                        <mxPoint x="-62" as="offset"/>
                    </mxGeometry>
                </mxCell>
                <object label="&lt;font color=&quot;#1565C0&quot;&gt;ðŸŽ“ TRAINED MODEL&lt;/font&gt;&#xa;&#xa;Base + LoRA Adapter&#xa;Merged &amp; Quantized (Q4_K_M)&#xa;Deployed to Ollama&#xa;web4-agent:latest" tooltip="The trained model is the final production artifact combining the base model general coding knowledge with the LoRA adapter Web4-specific patterns. Post-training process: merge LoRA adapter weights with base model weights, quantize merged model from FP16 to Q4_K_M format (4-bit with higher precision for critical attention layers), convert to GGUF format for optimized inference, create Ollama modelfile, and import to Ollama. The trained model capabilities include pattern recognition, code generation, PDCA creation, refactoring, guardrails, and collaboration. The 4GB quantized model loads in approximately 3 seconds on M1 Mac, generates at approximately 20 tokens per second, and achieves 90 percent accuracy on evaluation set metrics including pattern recognition 95 percent, PDCA template 95 percent, TRON format 90 percent, empty constructor 95 percent, CMM understanding 90 percent, historical retrieval 85 percent, refusal accuracy 98 percent, and overall score 90 percent." id="trained-model">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#E3F2FD;strokeColor=#1565C0;strokeWidth=4;fontSize=14;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="900" y="550" width="600" height="140" as="geometry"/>
                    </mxCell>
                </object>
                <mxCell id="arrow-runtime-rag" value="" style="endArrow=classic;startArrow=classic;html=1;rounded=0;strokeWidth=3;strokeColor=#FF6F00;exitX=0;exitY=0.75;exitDx=0;exitDy=0;entryX=1;entryY=0.75;entryDx=0;entryDy=0;dashed=1;" parent="1" source="trained-model" target="rag-architecture" edge="1">
                    <mxGeometry width="50" height="50" relative="1" as="geometry">
                        <mxPoint x="700" y="650" as="sourcePoint"/>
                        <mxPoint x="750" y="600" as="targetPoint"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="arrow-label-runtime" value="Runtime Queries&#xa;(10-20% PDCA history)&#xa;(30% tool injection)" style="edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];fontSize=11;fontStyle=1;fontColor=#FF6F00;fillColor=#FFF3E0;strokeColor=#FB8C00;rounded=1;" parent="arrow-runtime-rag" vertex="1" connectable="0">
                    <mxGeometry x="-0.05" y="1" relative="1" as="geometry">
                        <mxPoint y="-30" as="offset"/>
                    </mxGeometry>
                </mxCell>
                <object label="&lt;font color=&quot;#D84315&quot;&gt;ðŸŒ™ EVENING TRAINING LOOP&lt;/font&gt;&#xa;&#xa;Daily Buffer â†’ Query Untrained â†’ Generate Samples&#xa;â†’ Incremental Training (1 epoch) â†’ Mark as Trained&#xa;â†’ Move to Historical â†’ Clear Buffer&#xa;&#xa;Scheduled: 10 PM daily | Duration: 2-3 hours" tooltip="The evening training loop implements continuous learning, automatically incorporating each day work into the model every night at 10 PM. This creates a virtuous cycle where the model improves daily from real project work. The 7-step nightly process: Daily Buffer Collection throughout the day with new PDCAs indexed into daily_buffer with metadata. Query Untrained Patterns at 10 PM to identify what is new since yesterday. Generate Incremental Samples extracting patterns from today work with quality scoring. Incremental LoRA Training for these new samples for 1 epoch with adjusted hyperparameters, taking 2-3 hours for typical 50-sample daily batch. Mark as Trained updating RAG metadata for all trained chunks. Move to Historical with PDCAs from daily_buffer moved to pdca_historical collection and Redis Graph updated with new PRECEDES edges. Clear Daily Buffer with the collection archived and system reset for tomorrow. The evening loop advantages include continuous improvement, pattern discovery, adaptation, efficiency, and metadata-driven smart querying. Evening loop monitoring includes daily logs tracking sample count, training loss, memory usage, and completion time with alerting for issues." id="evening-loop">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#FFCCBC;strokeColor=#D84315;strokeWidth=4;fontSize=13;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="50" y="690" width="750" height="210" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#1B5E20&quot;&gt;ðŸš€ PRODUCTION DEPLOYMENT&lt;/font&gt;&#xa;&#xa;Ollama Model: web4-agent:latest&#xa;Fast Inference: ~20 tokens/sec on M1&#xa;Memory: ~4GB loaded&#xa;Response: 80-90% from training, 10-20% with RAG&#xa;Latency: under 200ms (trained), ~500ms (with RAG)" tooltip="Production deployment architecture optimizes for fast, reliable inference while maintaining access to historical context when needed. Ollama Integration provides REST API for LLM queries, chat interface for interactive sessions, and embedding endpoint for RAG similarity search. Ollama handles model lifecycle, request batching, and response streaming. Performance Characteristics include fast inference at approximately 20 tokens per second on M1 Mac, low memory footprint of approximately 4GB loaded, quick cold start of approximately 3 seconds to load model, and sub-200ms response latency for trained knowledge queries not requiring RAG. Decision Logic for RAG: the model first attempts to answer from trained knowledge (80-90 percent of queries), and for queries requiring specific historical context, the model queries RAG (10-20 percent of queries). RAG augmentation adds approximately 300ms latency but provides accurate historical reference. Hybrid Response Generation retrieves 3-5 relevant chunks, formats retrieved context, generates response incorporating both trained knowledge and retrieved facts, and includes source citations for traceability. Monitoring and Observability tracks response time metrics, RAG hit rate, quality metrics, and user feedback. Error handling gracefully degrades if RAG is unavailable, times out slow RAG queries, caches frequently accessed PDCAs, and logs all errors for analysis." id="production">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#C8E6C9;strokeColor=#2E7D32;strokeWidth=4;fontSize=13;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="1580" y="550" width="770" height="210" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#01579B&quot;&gt;ðŸ“Š KEY SUCCESS METRICS&lt;/font&gt;&#xa;&#xa;Training: Loss 0.6-1.0 | Memory under 28GB | 37K samples | ~20M tokens | 8-11 hrs&#xa;Quality: Pattern Recognition â‰¥95% | PDCA Template â‰¥95% | Framework Compliance â‰¥95%&#xa;Production: Response under 200ms | PDCA Queries 10-20% | Tool Queries 30% | Compilation â‰¥90% | Refusal â‰¥98%" tooltip="Key Success Metrics define measurable targets across three phases with hybrid tool architecture. Training Success includes loss convergence to 0.6-1.0 range indicating good learning, memory usage staying under 28GB ensuring stable training, successfully training 37K samples (down from 46K) in 8-11 hours (20 percent faster) validating the optimized token budget, and gradient norms staying stable confirming proper learning. Quality Success includes Pattern Recognition at least 95 percent measuring whether the model correctly identifies when to apply Web4 patterns, PDCA Template at least 95 percent evaluating generated PDCAs for completeness and compliance, Framework Compliance at least 95 percent checking generated code for proper architecture and conventions, Empty Constructor at least 95 percent for pattern adherence, CMM Understanding at least 90 percent for framework knowledge, Historical Retrieval at least 85 percent for RAG integration, and Refusal Accuracy at least 98 percent for guardrail effectiveness. Production Success includes response latency under 200ms for trained knowledge queries (no RAG), PDCA History Queries 10-20 percent of total requests validating historical reference usage, Tool Queries 30 percent of requests requiring tool example injection from RAG, Tool Injection Latency approximately 150ms additional for tool queries, Compilation Success at least 90 percent measuring whether generated code compiles on first attempt, and IDE Switching Time 5 minutes to swap Continue for Cursor versus 10-14 hours retraining. These metrics are continuously monitored via automated evaluation pipeline with alerting if any metric drops below threshold." id="metrics">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#E1F5FE;strokeColor=#0277BD;strokeWidth=3;fontSize=12;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="50" y="950" width="2300" height="110" as="geometry"/>
                    </mxCell>
                </object>
                <mxCell id="footer" value="ðŸŽ¯ Hybrid Tool Architecture: Train patterns + methodology (37K samples, ~20M tokens, 95% Web4) | 12K tool examples in RAG (swappable) | Reference history (534 PDCAs) | Learn continuously (evening loop) | 5-min IDE switching vs 10-14hr retraining" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#FFF9C4;strokeColor=#F57F17;strokeWidth=3;align=center;verticalAlign=middle;fontSize=13;fontStyle=1" parent="1" vertex="1">
                    <mxGeometry x="50" y="1090" width="2300" height="60" as="geometry"/>
                </mxCell>
            </root>
        </mxGraphModel>
    </diagram>
    <diagram name="RAG-First Training Pipeline" id="pipeline-flow">
        <mxGraphModel dx="2596" dy="855" grid="1" gridSize="10" guides="1" tooltips="1" connect="1" arrows="1" fold="1" page="1" pageScale="1" pageWidth="2400" pageHeight="1800" math="0" shadow="0">
            <root>
                <mxCell id="0"/>
                <mxCell id="1" parent="0"/>
                <mxCell id="flow-title" value="Web4 RAG-First Training Pipeline Flow" style="text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontSize=32;fontStyle=1" parent="1" vertex="1">
                    <mxGeometry x="400" y="20" width="1600" height="50" as="geometry"/>
                </mxCell>
                <mxCell id="flow-subtitle" value="End-to-End Journey: Data â†’ RAG â†’ Training â†’ Production â†’ Continuous Learning | Timeline: Day 1 Bootstrap â†’ Week 1-2 Sample Generation â†’ 8-11 Hours Training â†’ Production Deployment â†’ Nightly Improvements" style="text;html=1;strokeColor=none;fillColor=#E3F2FD;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=1;fontSize=16;fontStyle=2" parent="1" vertex="1">
                    <mxGeometry x="200" y="80" width="2000" height="35" as="geometry"/>
                </mxCell>
                <object label="&lt;font color=&quot;#01579B&quot;&gt;PHASE 0: BOOTSTRAP RAG&lt;/font&gt;&#xa;&#xa;Day 1 | Duration: ~1 hour&#xa;&#xa;Install: ChromaDB + Redis Graph + SQLite&#xa;Index: 534 PDCAs â†’ ~2,670 chunks&#xa;Index: 3,477 TypeScript files&#xa;Index: 238 process docs&#xa;Index: 12K tool examples&#xa;&#xa;Result: Complete RAG data store" tooltip="Phase 0 bootstraps the three-tier RAG system which serves as the single source of truth for all training data. Day 1 setup takes approximately 1 hour. Install dependencies: ChromaDB for semantic search, Redis server with RedisGraph module for breadcrumb navigation, SQLite for temporal queries. Run initial indexing scripts: all 534 historical PDCAs are processed with PDCA-aware adaptive chunking creating approximately 2,670 semantically complete chunks with 15+ metadata fields per chunk. The 3,477 TypeScript component files are indexed by layer and pattern. The 238 process documents including PDCA templates, CMM guides, and compliance checklists are indexed by role. The 12K tool examples from tool_core.jsonl and tool_neg.jsonl are indexed into the tool_examples collection with metadata for tool_name, tool_ecosystem, tool_version, usage_pattern, and context_type. Verify three-tier indexing: test semantic queries on ChromaDB, test breadcrumb traversal on Redis Graph, test temporal queries on SQLite. Test retrieval across all three tiers with sample queries. Result: Complete RAG data store ready for intelligent sample generation. This phase is critical because RAG becomes the single source of truth - all subsequent training samples are generated via queries against this RAG system, ensuring consistency and enabling metadata-driven sampling." id="phase0">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#E1F5FE;strokeColor=#01579B;strokeWidth=4;fontSize=13;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="100" y="150" width="360" height="220" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#F57F17&quot;&gt;PHASE 1: RAG-DRIVEN SAMPLE GENERATION&lt;/font&gt;&#xa;&#xa;Week 1-2 | Duration: ~10 days&#xa;&#xa;Query RAG for patterns (semantic + graph + temporal)&#xa;Generate 37K training samples:&#xa;â€¢ style_core: 12K&#xa;â€¢ domain_patterns: 8K&#xa;â€¢ process_framework: 5K&#xa;â€¢ domain_representatives: 3K&#xa;â€¢ style_refactor: 3K&#xa;â€¢ guardrails: 2K&#xa;â€¢ eval: 2K&#xa;â€¢ tool_awareness: 1K&#xa;&#xa;Save to JSONL files (~20M tokens)&#xa;&#xa;Result: Complete training dataset" tooltip="Phase 1 generates all 37K training samples via intelligent RAG queries over 10 days. This is the core innovation: RAG is not just for runtime retrieval but also the source for training sample generation. The process uses semantic queries to extract patterns, graph expansion to include context, and temporal filtering to ensure diversity. Sample generation per bucket: style_core 12K samples query ChromaDB for TypeScript files filtered by layer and pattern, extracting empty constructor examples, 5-layer architecture, Radical OOP, scenario-based state management. domain_patterns 8K samples query historical PDCAs semantically for problem-solution pairs, then use Redis Graph to walk breadcrumb chains for context, extracting distilled patterns. process_framework 5K samples extract PDCA structure, TRON format, CMM compliance from process_docs collection. domain_representatives 3K samples select top 200-300 PDCAs by quality score ensuring diverse time periods via SQLite temporal queries. style_refactor 3K samples query for CMM2 to CMM3 transformation PDCAs. guardrails 2K samples extract from violation reports. eval 2K samples stratify across all categories, NEVER trained. tool_awareness 1K samples curate generic tool concepts from tool_core.jsonl. Each sample includes input prompt, expected output, and metadata. Samples are saved to JSONL files totaling approximately 20M tokens. Quality checks validate schema compliance, Web4 pattern adherence, token distribution. Result: Production-ready training dataset generated entirely from RAG queries, ensuring consistency and traceability." id="phase1">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#FFF9C4;strokeColor=#F57F17;strokeWidth=4;fontSize=13;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="540" y="150" width="360" height="370" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#2E7D32&quot;&gt;PHASE 2: LORA TRAINING&lt;/font&gt;&#xa;&#xa;Week 3 | Duration: 8-11 hours&#xa;&#xa;Base: Qwen2.5-Coder-7B-Instruct (HuggingFace)&#xa;Train: 37K samples, 2 epochs&#xa;Config: r=16, alpha=32, dropout=0.05&#xa;Batch: 1 with grad accumulation 12&#xa;LR: 2e-4 with cosine schedule&#xa;Hardware: M1 Mac (32GB), MPS backend&#xa;&#xa;Monitor: Loss plateau 0.6-1.0&#xa;Monitor: Memory under 28GB&#xa;Monitor: Gradient norms stable&#xa;&#xa;Output: LoRA adapter (~80MB)&#xa;&#xa;Result: Trained Web4-specific adapter" tooltip="Phase 2 performs LoRA fine-tuning on the 37K samples generated from RAG queries. Training takes 8-11 hours on M1 Mac with 32GB RAM using MPS Metal Performance Shaders backend. Base model: Qwen/Qwen2.5-Coder-7B-Instruct from HuggingFace, chosen for strong code generation capabilities and 7 billion parameters optimized for coding. Training configuration: 37K samples trained for 2 full epochs totaling approximately 20M tokens. LoRA hyperparameters: rank r=16 creates small trainable matrices for efficient fine-tuning, alpha=32 for scaling, dropout=0.05 for regularization. Batch size 1 with gradient accumulation 12 gives effective batch size 12, enabling stable gradients while fitting in 32GB RAM. Learning rate 2e-4 with cosine annealing schedule gradually reduces learning rate for smooth convergence. The training pipeline loads JSONL files, tokenizes with the base model tokenizer, applies LoRA to attention and feedforward layers, and trains using AdamW optimizer. Real-time monitoring tracks loss convergence expecting plateau at 0.6-1.0 range indicating good learning without overfitting, memory usage must stay under 28GB to prevent OOM crashes, gradient norms should remain stable confirming proper learning dynamics. Training output: LoRA adapter approximately 80MB containing learned Web4-specific patterns without modifying the 14GB base model. The adapter encodes: 95 percent Web4-specific patterns including PDCA methodology, code architecture, OOP principles, 3 percent generic tool awareness, 2 percent guardrails. Result: Production-ready LoRA adapter ready for merging and quantization." id="phase2">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#C8E6C9;strokeColor=#2E7D32;strokeWidth=4;fontSize=13;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="980" y="150" width="360" height="370" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#1565C0&quot;&gt;PHASE 3: MERGE AND QUANTIZE&lt;/font&gt;&#xa;&#xa;Week 3 | Duration: ~2 hours&#xa;&#xa;Merge: LoRA adapter + Base model&#xa;Quantize: FP16 â†’ Q4_K_M (4-bit)&#xa;Convert: GGUF format&#xa;Size: 14GB â†’ 4GB (4x smaller)&#xa;Quality: 95% retained&#xa;&#xa;Create: Ollama modelfile&#xa;Import: web4-agent:latest&#xa;&#xa;Test: Load time ~3 seconds&#xa;Test: Generation ~20 tokens/sec&#xa;&#xa;Result: Deployable 4GB GGUF model" tooltip="Phase 3 merges the trained LoRA adapter with the base model and quantizes for efficient deployment. Duration approximately 2 hours. Merge process: The 80MB LoRA adapter weights are merged into the 14GB base model weights creating a unified model with Web4-specific knowledge permanently integrated. The merged model combines general coding knowledge from Qwen2.5-Coder with Web4-specific patterns from LoRA training. Quantization: Convert merged model from FP16 full precision to Q4_K_M 4-bit quantization. Q4_K_M uses 4-bit integers for most weights while keeping higher precision for critical attention layers, achieving optimal balance between size and quality. Size reduction: 14GB FP16 model compresses to 4GB Q4_K_M, a 4x reduction enabling deployment on consumer hardware. Quality retention: Quantization maintains 95 percent of full precision quality, validated through evaluation metrics. Convert to GGUF format: GGUF is an efficient file format for LLM storage optimized for CPU and Metal GPU inference, used by Ollama. Create Ollama modelfile: Define model configuration, system prompt, temperature, context window, and other parameters. Import to Ollama: Register the quantized GGUF model as web4-agent:latest in the local Ollama model registry. Test deployment: Verify load time approximately 3 seconds on M1 Mac cold start, generation speed approximately 20 tokens per second, memory footprint approximately 4GB loaded. Result: Production-ready 4GB GGUF model deployed to Ollama, ready for local inference with fast performance and low memory footprint." id="phase3">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#BBDEFB;strokeColor=#1565C0;strokeWidth=4;fontSize=13;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="1450" y="160" width="360" height="360" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#6A1B9A&quot;&gt;PHASE 4: EVALUATION AND QUALITY GATES&lt;/font&gt;&#xa;&#xa;Week 3 | Duration: ~4 hours&#xa;&#xa;Run: 2K eval samples (hold-out set)&#xa;&#xa;Test Harnesses:&#xa;âœ“ Pattern Compliance â‰¥95% (schema validator)&#xa;âœ“ PDCA Template â‰¥95% (section regex)&#xa;âœ“ TRON Format â‰¥90% (structure detector)&#xa;âœ“ Empty Constructor â‰¥95% (ESLint + AST)&#xa;âœ“ Tool Success â‰¥85% (100 scripted tasks)&#xa;âœ“ Refusal F1 â‰¥0.98 (200-item safety set)&#xa;âœ“ Overall â‰¥90%&#xa;&#xa;Canary Tests: 20 must-not-regress tasks&#xa;&#xa;Pass? â†’ Deploy | Fail? â†’ Rollback&#xa;&#xa;Result: Quality-validated model" tooltip="Phase 4 runs comprehensive evaluation to validate model quality before production deployment. Duration approximately 4 hours. Evaluation process: Run the 2K eval samples that were held out during training, ensuring unbiased quality measurement across all training categories. Test Harness 1 Pattern Compliance: Schema validator plus AST checker tests 100 generated PDCAs against v3.2.4.2 schema, must pass 95 out of 100. Test Harness 2 PDCA Template: Section regex plus metadata validator checks all required sections Links Plan Do Check Act Meta, must pass 95 out of 100. Test Harness 3 TRON Format: Structure detector validates Trigger Response Outcome Next ordering in decisions, must pass 90 out of 100. Test Harness 4 Empty Constructor: ESLint with Web4 rules plus AST parser checks no-constructor-logic rule on 100 generated classes, must pass 95 out of 100. Test Harness 5 Tool Success: 100 scripted IDE tasks measured end-to-end from prompt to correct tool JSON to successful execution in sandbox, must pass 85 out of 100. Test Harness 6 Refusal Accuracy: F1 score on 200-item curated safety set with 100 should-refuse and 100 should-comply samples, must achieve F1 at least 0.98. Overall Score: Weighted average of all metrics must be at least 90 percent. Canary Tests: Run 20 critical must-not-regress tasks comparing new model against baseline, fail if any regression over 5 percent. Gate Decision: If all Ship Gates pass (Pattern, PDCA, Empty Constructor, Refusal, Overall), proceed to production deployment. If any gate fails, halt deployment, rollback to last-known-good adapter, create incident PDCA documenting failure mode, investigate root cause, fix and retry. Result: Quality-validated model ready for production with documented test results." id="phase4">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#F3E5F5;strokeColor=#6A1B9A;strokeWidth=4;fontSize=13;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="1900" y="130" width="380" height="420" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#558B2F&quot;&gt;PHASE 5: PRODUCTION DEPLOYMENT&lt;/font&gt;&#xa;&#xa;Week 3 | Duration: ~1 hour&#xa;&#xa;Deploy: web4-agent:latest to Ollama&#xa;Connect: RAG system for historical queries&#xa;Configure: ToolAwarePromptBuilder&#xa;Start: Ollama server&#xa;&#xa;Response Logic:&#xa;â€¢ 80-90% queries: From training (under 200ms)&#xa;â€¢ 10-20% queries: With RAG PDCA history (+300ms)&#xa;â€¢ 30% queries: With RAG tool injection (+150ms)&#xa;&#xa;Monitor: Response time, RAG hit rate, quality&#xa;&#xa;Result: Production-ready system" tooltip="Phase 5 deploys the validated model to production with full RAG integration. Duration approximately 1 hour. Deployment steps: Deploy web4-agent:latest GGUF model to Ollama model registry. Connect RAG system for historical reference: ChromaDB for semantic search, Redis Graph for breadcrumb navigation, SQLite for temporal queries. Configure ToolAwarePromptBuilder to inject relevant tool examples from the 12K tool_examples RAG collection at runtime. Start Ollama server with REST API for LLM queries, chat interface for interactive sessions, and embedding endpoint for RAG similarity. Response logic: The model first attempts to answer from trained knowledge covering 80-90 percent of queries with response latency under 200ms. For queries requiring specific historical context like how did we solve X before or what did we work on date Y, the model queries RAG adding approximately 300ms latency but providing accurate historical reference with source citations. For queries requiring tool usage like read this file or run this command, ToolAwarePromptBuilder detects tool need, queries RAG tool_examples collection for 2-3 relevant examples, injects examples into context adding approximately 150ms latency, and model generates correct tool call following RAG-provided patterns. Monitoring: Track response time metrics across query types, RAG hit rate to validate 10-20 percent PDCA queries and 30 percent tool queries, quality metrics via user feedback and automated checks. Error handling: Gracefully degrade if RAG unavailable, timeout slow RAG queries after 1 second, cache frequently accessed PDCAs for speed. Result: Production-ready system combining fast inference from trained knowledge with accurate historical reference and flexible tool usage." id="phase5">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#DCEDC8;strokeColor=#689F38;strokeWidth=4;fontSize=13;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="100" y="680" width="480" height="320" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#D84315&quot;&gt;PHASE 6: EVENING TRAINING LOOP&lt;/font&gt;&#xa;&#xa;Nightly | Scheduled: 10 PM | Duration: 2-3 hours&#xa;&#xa;Step 1: Query daily_buffer for untrained patterns&#xa;Step 2: Quality scoring and pattern extraction&#xa;Step 3: Generate incremental samples (50-200)&#xa;Step 4: Incremental LoRA training (1 epoch)&#xa;Step 5: Canary test (validate no regressions)&#xa;Step 6: Mark as trained in RAG metadata&#xa;Step 7: Move PDCAs to pdca_historical&#xa;Step 8: Clear daily_buffer, archive logs&#xa;&#xa;Monitoring: Loss, memory, sample count, completion&#xa;Rollback: Keep last-5 adapters, auto-rollback on failure&#xa;&#xa;Result: Continuous daily improvement" tooltip="Phase 6 implements the evening training loop for continuous learning, running every night at 10 PM for 2-3 hours. This creates a virtuous cycle where the model improves daily from real project work. Step 1 Query Untrained: At 10 PM trigger, query daily_buffer collection for PDCAs and patterns added today. Filter by metadata trained_in_adapter equals False to identify new content. Typical daily yield: 50-200 new samples depending on activity. Step 2 Quality Scoring: Apply quality scoring to select high-value samples. Extract patterns from today work: new problem-solution pairs, refactoring journeys, architectural decisions. Step 3 Generate Samples: Create incremental training samples in JSONL format with input prompt, expected output, and metadata. Samples follow same schema as initial training for consistency. Step 4 Incremental Training: Train LoRA adapter on incremental samples for 1 epoch only with reduced learning rate 1e-4 to avoid catastrophic forgetting. Training takes 2-3 hours for typical 50-sample batch. Step 5 Canary Test: Before promoting new adapter, run 20 must-not-regress tasks comparing new adapter against baseline. Fail if any regression over 5 percent. Step 6 Mark as Trained: Update RAG metadata setting trained_in_adapter equals True, training_batch equals nightly_YYYYMMDD, training_date equals timestamp for all trained chunks. Step 7 Move to Historical: Move PDCAs from daily_buffer to pdca_historical collection. Update Redis Graph with new PRECEDES edges for breadcrumb navigation. Step 8 Clear and Archive: Archive daily_buffer to logs, clear collection, reset for tomorrow. Monitoring: Daily logs track sample count, training loss, memory usage, completion time. Alert on failures or anomalies. Rollback: Keep last-5 nightly adapters. If canary fails, auto-rollback to last-known-good adapter and create incident PDCA. Result: Model continuously improves from daily work while maintaining quality through canary tests and rollback protection." id="phase6">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#FFCCBC;strokeColor=#D84315;strokeWidth=4;fontSize=13;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="790" y="680" width="520" height="420" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#4A148C&quot;&gt;CONTINUOUS OPERATION&lt;/font&gt;&#xa;&#xa;Daily Workflow:&#xa;&#xa;09:00 - 22:00: Production serving&#xa;  â€¢ Answer user queries&#xa;  â€¢ Generate code and PDCAs&#xa;  â€¢ New work indexed to daily_buffer&#xa;&#xa;22:00 - 01:00: Evening training&#xa;  â€¢ Train today patterns&#xa;  â€¢ Update model&#xa;  â€¢ Quality gates&#xa;&#xa;01:00 - 09:00: Production serving&#xa;  â€¢ Improved model in production&#xa;  â€¢ New patterns available&#xa;&#xa;Result: Self-improving system" tooltip="Continuous operation shows the daily rhythm of the Web4 training system. During daytime 09:00 to 22:00, the production model serves user queries, generates code following Web4 patterns, creates PDCAs with proper structure, and provides historical context via RAG when needed. All new work created during the day including PDCAs, code, decisions, and learnings are automatically indexed into the daily_buffer RAG collection with metadata. At night 22:00 to 01:00, the evening training loop activates: query daily_buffer for untrained patterns, extract and score patterns, generate incremental training samples typically 50-200 samples, train LoRA adapter for 1 epoch with reduced learning rate, run canary tests to validate no regressions, mark trained data in RAG metadata, move PDCAs to historical collection, clear daily_buffer. If all quality gates pass, the improved adapter is promoted to production. If canary fails, rollback to previous adapter and create incident PDCA. From 01:00 to 09:00 next morning, the improved model is in production with yesterday patterns now trained in. Users benefit from model that learned from yesterday work. This cycle repeats daily creating a self-improving system. Benefits: Continuous improvement from real project work, pattern discovery from daily activities, adaptation to evolving practices, efficient incremental learning without full retraining, metadata-driven sample selection ensures quality. The system gets smarter every day while maintaining production stability through canary tests and rollback protection. Over time, the model accumulates deep Web4 domain expertise from hundreds of days of project work." id="continuous">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#E1BEE7;strokeColor=#7B1FA2;strokeWidth=4;fontSize=13;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="1570" y="780" width="420" height="320" as="geometry"/>
                    </mxCell>
                </object>
                <mxCell id="arrow-phase0-phase1" value="" style="endArrow=classic;html=1;rounded=0;strokeWidth=4;strokeColor=#01579B;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=0;entryY=0.5;entryDx=0;entryDy=0;" parent="1" source="phase0" target="phase1" edge="1">
                    <mxGeometry width="50" height="50" relative="1" as="geometry">
                        <mxPoint x="460" y="260" as="sourcePoint"/>
                        <mxPoint x="520" y="260" as="targetPoint"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="label-phase0-1" value="RAG Ready" style="edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];fontSize=11;fontStyle=1;fontColor=#01579B;fillColor=#E1F5FE;strokeColor=#0288D1;rounded=1;" parent="arrow-phase0-phase1" vertex="1" connectable="0">
                    <mxGeometry x="-0.1" y="1" relative="1" as="geometry">
                        <mxPoint as="offset"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="arrow-phase1-phase2" value="" style="endArrow=classic;html=1;rounded=0;strokeWidth=4;strokeColor=#F57F17;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=0;entryY=0.5;entryDx=0;entryDy=0;" parent="1" source="phase1" target="phase2" edge="1">
                    <mxGeometry width="50" height="50" relative="1" as="geometry">
                        <mxPoint x="880" y="300" as="sourcePoint"/>
                        <mxPoint x="940" y="300" as="targetPoint"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="label-phase1-2" value="37K Samples&#xa;~20M Tokens" style="edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];fontSize=11;fontStyle=1;fontColor=#F57F17;fillColor=#FFF9C4;strokeColor=#F9A825;rounded=1;" parent="arrow-phase1-phase2" vertex="1" connectable="0">
                    <mxGeometry x="-0.1" y="1" relative="1" as="geometry">
                        <mxPoint as="offset"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="arrow-phase2-phase3" value="" style="endArrow=classic;html=1;rounded=0;strokeWidth=4;strokeColor=#2E7D32;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=0;entryY=0.5;entryDx=0;entryDy=0;" parent="1" source="phase2" target="phase3" edge="1">
                    <mxGeometry width="50" height="50" relative="1" as="geometry">
                        <mxPoint x="1300" y="340" as="sourcePoint"/>
                        <mxPoint x="1360" y="340" as="targetPoint"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="label-phase2-3" value="LoRA Adapter&#xa;80MB" style="edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];fontSize=11;fontStyle=1;fontColor=#2E7D32;fillColor=#C8E6C9;strokeColor=#43A047;rounded=1;" parent="arrow-phase2-phase3" vertex="1" connectable="0">
                    <mxGeometry x="-0.1" y="1" relative="1" as="geometry">
                        <mxPoint as="offset"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="arrow-phase3-phase4" value="" style="endArrow=classic;html=1;rounded=0;strokeWidth=4;strokeColor=#1565C0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=0;entryY=0.5;entryDx=0;entryDy=0;" parent="1" source="phase3" target="phase4" edge="1">
                    <mxGeometry width="50" height="50" relative="1" as="geometry">
                        <mxPoint x="1720" y="300" as="sourcePoint"/>
                        <mxPoint x="1780" y="300" as="targetPoint"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="label-phase3-4" value="GGUF Model&#xa;4GB" style="edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];fontSize=11;fontStyle=1;fontColor=#1565C0;fillColor=#BBDEFB;strokeColor=#1976D2;rounded=1;" parent="arrow-phase3-phase4" vertex="1" connectable="0">
                    <mxGeometry x="-0.1" y="1" relative="1" as="geometry">
                        <mxPoint as="offset"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="arrow-phase4-phase5" value="" style="endArrow=classic;html=1;rounded=0;strokeWidth=4;strokeColor=#6A1B9A;exitX=0.5;exitY=1;exitDx=0;exitDy=0;entryX=0.454;entryY=0.006;entryDx=0;entryDy=0;entryPerimeter=0;" parent="1" source="phase4" target="phase5" edge="1">
                    <mxGeometry width="50" height="50" relative="1" as="geometry">
                        <mxPoint x="1780" y="570" as="sourcePoint"/>
                        <mxPoint x="580" y="500" as="targetPoint"/>
                        <Array as="points">
                            <mxPoint x="2090" y="620"/>
                            <mxPoint x="1780" y="620"/>
                            <mxPoint x="1200" y="620"/>
                            <mxPoint x="320" y="620"/>
                        </Array>
                    </mxGeometry>
                </mxCell>
                <mxCell id="label-phase4-5" value="Quality Validated&#xa;All Gates Pass âœ“" style="edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];fontSize=11;fontStyle=1;fontColor=#6A1B9A;fillColor=#F3E5F5;strokeColor=#8E24AA;rounded=1;" parent="arrow-phase4-phase5" vertex="1" connectable="0">
                    <mxGeometry x="-0.1" y="1" relative="1" as="geometry">
                        <mxPoint x="320" y="-10" as="offset"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="arrow-phase5-phase6" value="" style="endArrow=classic;html=1;rounded=0;strokeWidth=4;strokeColor=#558B2F;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=0;entryY=0.5;entryDx=0;entryDy=0;" parent="1" source="phase5" target="phase6" edge="1">
                    <mxGeometry width="50" height="50" relative="1" as="geometry">
                        <mxPoint x="580" y="840" as="sourcePoint"/>
                        <mxPoint x="640" y="840" as="targetPoint"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="label-phase5-6" value="Daily Work&#xa;â†’ daily_buffer" style="edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];fontSize=11;fontStyle=1;fontColor=#558B2F;fillColor=#DCEDC8;strokeColor=#689F38;rounded=1;" parent="arrow-phase5-phase6" vertex="1" connectable="0">
                    <mxGeometry x="-0.1" y="1" relative="1" as="geometry">
                        <mxPoint as="offset"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="arrow-phase6-continuous" value="" style="endArrow=classic;html=1;rounded=0;strokeWidth=4;strokeColor=#D84315;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=0;entryY=0.5;entryDx=0;entryDy=0;" parent="1" source="phase6" target="continuous" edge="1">
                    <mxGeometry width="50" height="50" relative="1" as="geometry">
                        <mxPoint x="1160" y="710" as="sourcePoint"/>
                        <mxPoint x="1220" y="760" as="targetPoint"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="label-phase6-cont" value="Improved Model&#xa;Every Night" style="edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];fontSize=11;fontStyle=1;fontColor=#D84315;fillColor=#FFCCBC;strokeColor=#FF5722;rounded=1;" parent="arrow-phase6-continuous" vertex="1" connectable="0">
                    <mxGeometry x="-0.1" y="1" relative="1" as="geometry">
                        <mxPoint as="offset"/>
                    </mxGeometry>
                </mxCell>
                <mxCell id="arrow-continuous-loop" value="" style="endArrow=classic;html=1;rounded=0;strokeWidth=3;strokeColor=#7B1FA2;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=0.456;entryY=0.996;entryDx=0;entryDy=0;dashed=1;entryPerimeter=0;" parent="1" source="continuous" target="phase5" edge="1">
                    <mxGeometry width="50" height="50" relative="1" as="geometry">
                        <mxPoint x="1640" y="940" as="sourcePoint"/>
                        <mxPoint x="1700" y="940" as="targetPoint"/>
                        <Array as="points">
                            <mxPoint x="2080" y="940"/>
                            <mxPoint x="2080" y="1150"/>
                            <mxPoint x="319" y="1160"/>
                        </Array>
                    </mxGeometry>
                </mxCell>
                <mxCell id="label-loop" value="Continuous&#xa;Daily Cycle" style="edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];fontSize=11;fontStyle=1;fontColor=#7B1FA2;fillColor=#E1BEE7;strokeColor=#8E24AA;rounded=1;" parent="arrow-continuous-loop" vertex="1" connectable="0">
                    <mxGeometry x="-0.1" y="1" relative="1" as="geometry">
                        <mxPoint x="15" as="offset"/>
                    </mxGeometry>
                </mxCell>
                <object label="&lt;font color=&quot;#BF360C&quot;&gt;âš ï¸ FAILURE HANDLING&lt;/font&gt;&#xa;&#xa;Quality Gate Failure (Phase 4):&#xa;â€¢ Halt deployment immediately&#xa;â€¢ Keep current production model&#xa;â€¢ Rollback to last-known-good adapter&#xa;â€¢ Create incident PDCA&#xa;â€¢ Root cause analysis&#xa;â€¢ Fix issues and retry&#xa;&#xa;Canary Test Failure (Phase 6):&#xa;â€¢ Auto-rollback to previous adapter&#xa;â€¢ Create incident PDCA&#xa;â€¢ Alert on-call&#xa;â€¢ Investigate training data quality&#xa;â€¢ Skip tonight update, retry tomorrow" tooltip="Failure handling ensures production stability when quality gates or canary tests fail. Quality Gate Failure in Phase 4: If any ship gate fails during evaluation Pattern Compliance under 95 percent, PDCA Template under 95 percent, Refusal F1 under 0.98, or Overall under 90 percent, immediately halt deployment. Keep current production model serving traffic. Rollback training to last-known-good adapter saved from previous successful training. Create incident PDCA documenting which gate failed, by how much, sample failures, and initial observations. Conduct root cause analysis: inspect training data quality, review hyperparameters, check for data distribution shifts, validate evaluation harness correctness. Fix identified issues: curate better training samples, adjust hyperparameters, fix bugs in data pipeline. Retry training after fixes applied. Do not deploy to production until all gates pass. Canary Test Failure in Phase 6: If nightly canary test detects regression over 5 percent on any of 20 must-not-regress tasks, automatically rollback to previous nightly adapter without human intervention. Create incident PDCA documenting which canary task regressed, baseline score, new score, and regression magnitude. Alert on-call engineer via PagerDuty or Slack for investigation. Investigate training data quality from today daily_buffer: were there low-quality samples, outliers, or distribution shifts. Skip tonight evening loop update, keeping yesterday model in production. Retry tomorrow night after data quality issues addressed. The system maintains last-5 nightly adapters enabling rollback to any recent version. Failure handling philosophy: Fail closed, never deploy broken model. Automate rollback for speed. Document failures for learning. Investigate root causes systematically. Production stability over feature velocity." id="failure">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#FFEBEE;strokeColor=#C62828;strokeWidth=3;fontSize=12;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="1700" y="1230" width="460" height="300" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#1B5E20&quot;&gt;ðŸ“Š TIMELINE SUMMARY&lt;/font&gt;&#xa;&#xa;Day 1: Bootstrap RAG (1 hour)&#xa;Week 1-2: Generate 37K samples from RAG queries (10 days)&#xa;Week 3: Train LoRA (8-11 hours) â†’ Merge and Quantize (2 hours) â†’ Evaluate (4 hours) â†’ Deploy (1 hour)&#xa;Week 3+: Production serving + Nightly improvements (continuous)&#xa;&#xa;Total Initial: ~3 weeks from zero to production&#xa;Continuous: Daily 2-3 hour training overnight, improved model every morning&#xa;&#xa;Key Innovation: RAG is both training data source AND runtime reference library" tooltip="Timeline summary shows the complete journey from zero to production in approximately 3 weeks. Day 1 Bootstrap: 1 hour to install ChromaDB, Redis Graph, SQLite and index all 534 PDCAs, 3,477 TypeScript files, 238 process docs, and 12K tool examples. This creates the three-tier RAG system as single source of truth. Week 1-2 Sample Generation: 10 days to generate all 37K training samples via intelligent RAG queries. Use semantic search, graph expansion, and temporal filtering to extract patterns, select representatives, and ensure diversity. Save to JSONL files totaling approximately 20M tokens. Week 3 Training: 8-11 hours to train LoRA adapter on 37K samples using M1 Mac with MPS backend. Monitor loss convergence, memory usage, gradient stability. Output: 80MB LoRA adapter. Week 3 Post-Processing: 2 hours to merge adapter with base model and quantize from FP16 to Q4_K_M 4GB GGUF. 4 hours to run comprehensive evaluation with 2K hold-out samples across 6 test harnesses and 20 canary tasks. 1 hour to deploy validated model to Ollama and configure RAG integration. Week 3+ Continuous Operation: Production serving during daytime with model answering queries, generating code, creating PDCAs. Daily work indexed to daily_buffer. Every night at 10 PM, evening training loop activates: extract patterns from daily_buffer, train incrementally for 1 epoch taking 2-3 hours, validate with canary tests, promote if passed. Improved model in production next morning. This cycle repeats indefinitely creating self-improving system. Key Innovation: RAG serves dual purpose as training data source during initial sample generation AND runtime reference library for historical queries and tool injection. This ensures consistency between training and deployment. Total timeline: 3 weeks initial setup, then continuous daily improvements forever." id="timeline">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#E8F5E9;strokeColor=#2E7D32;strokeWidth=3;fontSize=12;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="100" y="1230" width="840" height="240" as="geometry"/>
                    </mxCell>
                </object>
                <object label="&lt;font color=&quot;#004D40&quot;&gt;ðŸ’¡ KEY BENEFITS&lt;/font&gt;&#xa;&#xa;âœ“ Single Source of Truth: RAG for both training and runtime&#xa;âœ“ Metadata-Driven: Intelligent sampling via semantic + graph + temporal&#xa;âœ“ Quality Assurance: 6 test harnesses + 20 canary tasks&#xa;âœ“ Continuous Learning: Nightly improvements from daily work&#xa;âœ“ Production Stability: Canary tests + auto-rollback&#xa;âœ“ Token Efficiency: 37K samples, 20M tokens, 95% Web4-focused&#xa;âœ“ Fast Training: 8-11 hours (20% faster than 46K/25M approach)&#xa;âœ“ Hybrid Tools: 1K trained + 12K RAG for IDE flexibility&#xa;âœ“ Self-Improving: Gets smarter every day, learns from real work" tooltip="Key benefits of the RAG-first training pipeline. Single Source of Truth: RAG serves as the authoritative data source for both initial training sample generation and runtime historical queries, ensuring consistency and traceability. All 37K training samples are generated via RAG queries, not from raw files. Metadata-Driven Sampling: Intelligent sample generation combines semantic search to find patterns, graph expansion to include context, and temporal filtering to ensure diversity. Metadata fields enable precise filtering by CMM level, task type, agent, date, and quality score. Quality Assurance: Comprehensive evaluation with 6 automated test harnesses Pattern Compliance, PDCA Template, TRON Format, Empty Constructor, Tool Success, Refusal F1 plus 20 canary tasks for must-not-regress validation. Binary pass fail gates prevent broken models from reaching production. Continuous Learning: The evening training loop runs nightly extracting patterns from today daily_buffer, training incrementally for 1 epoch, and promoting improved adapter to production every morning. Model gets smarter from real project work. Production Stability: Canary tests validate no regressions before promoting nightly adapters. Auto-rollback on failure keeps production stable. Keep last-5 adapters for safety. Token Efficiency: Optimized 37K samples with 20M tokens (reduced from 46K/25M) achieves 95 percent Web4-specific focus versus 74 percent in old approach. Distillation and RAG storage save 5M tokens. Fast Training: 8-11 hours full training on M1 Mac is 20 percent faster than previous 10-14 hours, enabled by reduced token count and optimized sampling. Hybrid Tool Architecture: Train 1K generic tool awareness, store 12K IDE-specific examples in RAG. Switch IDEs in 5 minutes versus 10-14 hours retraining. Supports Continue, Cursor, and custom tools simultaneously. Self-Improving System: The model accumulates deep Web4 domain expertise from hundreds of days of project work, learning from successes and failures, adapting to evolving practices, discovering new patterns organically." id="benefits">
                    <mxCell style="rounded=1;whiteSpace=wrap;html=1;fillColor=#E0F2F1;strokeColor=#00695C;strokeWidth=3;fontSize=12;fontStyle=1;verticalAlign=top;spacingTop=15;" parent="1" vertex="1">
                        <mxGeometry x="1000" y="1230" width="640" height="300" as="geometry"/>
                    </mxCell>
                </object>
                <mxCell id="flow-footer" value="ðŸŽ¯ RAG-First Philosophy: RAG as Single Source of Truth for Training and Runtime | Intelligent Sampling via Semantic + Graph + Temporal Queries | Quality Gates at Every Step | Continuous Learning from Daily Work | Production Stability via Canary Tests and Auto-Rollback" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#E3F2FD;strokeColor=#1565C0;strokeWidth=3;align=center;verticalAlign=middle;fontSize=13;fontStyle=1" parent="1" vertex="1">
                    <mxGeometry x="100" y="1590" width="2060" height="60" as="geometry"/>
                </mxCell>
            </root>
        </mxGraphModel>
    </diagram>
</mxfile>